{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQhuzTMgePeq"
      },
      "source": [
        "개미는.. 뚠뚠.. 오늘도.. 뚠뚠.. 데이터를.. 까본다네.. ^ㅜ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq6_sVEzeXmN"
      },
      "source": [
        "# import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XMg832-G3-DO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDxtKj3i3zkK"
      },
      "source": [
        "# Data Load\n",
        ": google colab 환경에서 data 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e80G56en363o",
        "outputId": "c9dc85c3-383b-45b5-b16b-c97fdd5c0021"
      },
      "outputs": [],
      "source": [
        "# 구글 드라이브 공유 링크에서 파일 ID를 가져옵니다.\n",
        "file_id = '1ZUueEhjvhzmo8UpZLwqMgzMKA6FGtLJk'  # 여기에 파일 ID를 입력하세요.\n",
        "download_url = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "\n",
        "# 파일 다운로드\n",
        "response = requests.get(download_url)\n",
        "response.raise_for_status()  # 요청이 실패하면 예외를 발생시킵니다.\n",
        "\n",
        "# 다운로드한 ZIP 파일을 메모리에서 직접 압축 해제합니다.\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
        "    zip_ref.extractall('/content/unzipped_folder')\n",
        "\n",
        "# 결과 확인\n",
        "import os\n",
        "os.listdir('/content/unzipped_folder')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_y_UGK-04A_e"
      },
      "outputs": [],
      "source": [
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"/content/unzipped_folder/train.csv\")\n",
        "train = pd.read_csv(\"/content/unzipped_folder/train.csv\")\n",
        "test = pd.read_csv(\"/content/unzipped_folder/test.csv\")\n",
        "submission = pd.read_csv(\"/content/unzipped_folder/sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5IBks0BfQRM",
        "outputId": "2e35749b-9334-44bf-cb95-280fbc9dd258"
      },
      "outputs": [],
      "source": [
        "print(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By4KNvnygngI",
        "outputId": "0cd1ae17-9310-4891-fb92-b782f94fee0a"
      },
      "outputs": [],
      "source": [
        "print(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XWQierlgr_Y"
      },
      "source": [
        "# Data Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaJW0jC62Qq7"
      },
      "source": [
        "## 1 Binary Encoding\n",
        ": WT = 0, Variants = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 데이터 로드\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data preprocessing\n",
        "- WT = 0\n",
        "- Variants = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 기존 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YOs1rT-fQTi",
        "outputId": "7207daae-ae49-46ba-8b5b-e55b267102b5"
      },
      "outputs": [],
      "source": [
        "# WT는 0, 변이는 1로 변환하는 함수\n",
        "train_binary = train.replace('WT', 0)\n",
        "train_binary.iloc[:, 2:] = train_binary.iloc[:, 2:].applymap(lambda x: 1 if x != 0 else 0)\n",
        "print(train_binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 새로운 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "처리 후 train NaN 개수: 0\n",
            "처리 후 test NaN 개수: 0\n"
          ]
        }
      ],
      "source": [
        "# NaN 값을 'WT'로 치환\n",
        "train.fillna('WT', inplace=True)\n",
        "test.fillna('WT', inplace=True)\n",
        "\n",
        "train_nan = train.isna().sum().sum()\n",
        "print(f\"처리 후 train NaN 개수: {train_nan}\")\n",
        "\n",
        "test_nan = test.isna().sum().sum()\n",
        "print(f\"처리 후 test NaN 개수: {test_nan}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "def process_value_be(value):\n",
        "    # 0. WT 그대로 유지\n",
        "    if value == 'WT':\n",
        "        return 0\n",
        "\n",
        "    # 1. 띄어쓰기 기준으로 변이 파트 분리\n",
        "    parts = value.split()\n",
        "\n",
        "    for part in parts:\n",
        "        # 1.1 WT: 0\n",
        "        if part == 'WT':\n",
        "            continue\n",
        "\n",
        "        # 1.2 알파벳 + 숫자 + 알파벳\n",
        "        elif re.match(r'^([A-Za-z*-]*)\\d+([A-Za-z*-]*)$', part):\n",
        "            match = re.match(r'^([A-Za-z*-]*)\\d+([A-Za-z*-]*)$', part)\n",
        "            prefix = match.group(1)   # 숫자 앞의 문자 그룹\n",
        "            suffix = match.group(2)   # 숫자 뒤의 문자 그룹\n",
        "\n",
        "            # 1.2.1 숫자 앞뒤의 문자 그룹이 같으면 silent\n",
        "            if prefix.isupper() and suffix.isupper() and prefix == suffix:\n",
        "                continue\n",
        "\n",
        "            # 1.2.2 앞뒤 문자 그룹이 다르면 missense\n",
        "            elif prefix.isupper() and suffix.isupper() and prefix != suffix:\n",
        "                return 1\n",
        "\n",
        "            # 1.2.3 뒤의 문자 그룹에 '*'이 들어가면 nonsense\n",
        "            elif '*' in suffix:\n",
        "                return 1\n",
        "\n",
        "            # 1.2.4 뒤의 문자 그룹에 'fs'가 들어가면 frameshift\n",
        "            elif 'fs' in suffix:\n",
        "                return 1\n",
        "\n",
        "            # 1.2.5 뒤에 문자 그룹에 'del'이나 'ins'이 들어가면 indel\n",
        "            elif 'del' in suffix or 'ins' in suffix or not(suffix):\n",
        "                return 1\n",
        "\n",
        "            # 1.2.7 예외사항 출력\n",
        "            else:\n",
        "                print(part)\n",
        "\n",
        "        # 1.3 숫자_숫자알파벳>알파벳\n",
        "        elif re.match(r'^(\\d+)_(\\d+)([A-Za-z*-]+>[A-Za-z*-]+|del)$', part):\n",
        "            match = re.match(r'^(\\d+)_(\\d+)([A-Za-z*-]+>[A-Za-z*-]+|del)$', part)\n",
        "            prenum = int(match.group(1))  # 앞 위치\n",
        "            postnum = int(match.group(2))  # 뒷 위치\n",
        "            variant = match.group(3)  # 변이 정보 그룹\n",
        "\n",
        "            # 1.3.1 >가 있는 경우\n",
        "            if '>' in variant:\n",
        "                before, after = variant.split('>')  # '>' 기준으로 나눔\n",
        "\n",
        "                # 1.3.1.1 문자 그룹이 같은 경우 -> silent\n",
        "                if before.isupper() and after.isupper() and before == after:\n",
        "                    continue\n",
        "\n",
        "                # 1.3.1.2 *가 있는 경우 -> nonsense\n",
        "                elif '*' in after:\n",
        "                    return 1\n",
        "\n",
        "                # 1.3.1.3 문자 그룹이 다른 경우 -> missense\n",
        "                elif before.isupper() and after.isupper() and before != after:\n",
        "                    return 1\n",
        "\n",
        "                else:\n",
        "                    print(part)\n",
        "\n",
        "            # 1.3.2 > 대신 'del'이 있는 경우 -> indel\n",
        "            elif 'del' in variant:\n",
        "                return 1\n",
        "\n",
        "            # 1.3.3 예외사항 출력\n",
        "            else :\n",
        "                print(part)\n",
        "\n",
        "        # 1.4 알파벳숫자_알파벳숫자변이정보\n",
        "        elif re.match(r'^([A-Za-z]+)(\\d+)_([A-Za-z]+)?(\\d+)([A-Za-z]+)$', part):\n",
        "            match = re.match(r'^([A-Za-z]+)(\\d+)_([A-Za-z]+)?(\\d+)([A-Za-z]+)$', part)\n",
        "            prenum = int(match.group(2))   # 앞 위치\n",
        "            postnum = int(match.group(4))  # 뒷 위치\n",
        "            variant = match.group(5)  # 변이정보\n",
        "\n",
        "            # 1.4.1 'delins'가 있는 경우 -> indel\n",
        "            if 'del' in variant or 'ins' in variant:\n",
        "                return 1\n",
        "\n",
        "            # 1.4.4 예외사항 출력\n",
        "            else :\n",
        "                print(part)\n",
        "\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 유니크한 값: \n",
            "[0 1]\n",
            "test 유니크한 값: \n",
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "# train 데이터프레임 전처리\n",
        "for col in train.columns[2:]:  # ID와 SUBCLASS 제외\n",
        "    train[col] = train[col].apply(process_value_be)\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(train.iloc[:, 2:].values)\n",
        "print(\"train 유니크한 값: \")\n",
        "print(unique_values)\n",
        "\n",
        "# test 데이터프레임 전처리\n",
        "for col in test.columns[1:]:  # ID 제외\n",
        "    test[col] = test[col].apply(process_value_be)\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(test.iloc[:, 2:].values)\n",
        "print(\"test 유니크한 값: \")\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              ID SUBCLASS  A2M  AAAS  AADAT  AARS1  ABAT  ABCA1  ABCA2  ABCA3  \\\n",
            "0     TRAIN_0000    KIPAN    0     0      0      0     0      0      0      0   \n",
            "1     TRAIN_0001     SARC    0     0      0      0     0      0      0      0   \n",
            "2     TRAIN_0002     SKCM    0     0      0      0     0      0      0      0   \n",
            "3     TRAIN_0003     KIRC    0     0      0      0     0      0      0      0   \n",
            "4     TRAIN_0004   GBMLGG    0     0      0      0     0      0      0      0   \n",
            "...          ...      ...  ...   ...    ...    ...   ...    ...    ...    ...   \n",
            "6196  TRAIN_6196     LUAD    0     0      0      0     0      0      0      0   \n",
            "6197  TRAIN_6197      LGG    0     0      0      0     0      0      0      0   \n",
            "6198  TRAIN_6198     COAD    0     0      0      0     0      0      0      0   \n",
            "6199  TRAIN_6199     TGCT    0     0      0      0     0      0      0      0   \n",
            "6200  TRAIN_6200     SKCM    0     0      0      0     0      0      0      0   \n",
            "\n",
            "      ...  ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  \\\n",
            "0     ...       0       0       0       0      0      0     0     0      0   \n",
            "1     ...       0       0       0       0      0      0     0     0      0   \n",
            "2     ...       0       0       0       0      0      0     0     0      0   \n",
            "3     ...       0       0       0       0      0      0     0     0      0   \n",
            "4     ...       0       0       0       0      0      0     0     0      0   \n",
            "...   ...     ...     ...     ...     ...    ...    ...   ...   ...    ...   \n",
            "6196  ...       0       0       0       0      0      0     0     0      0   \n",
            "6197  ...       0       0       0       0      0      0     0     0      0   \n",
            "6198  ...       0       0       0       0      0      0     0     0      1   \n",
            "6199  ...       0       0       0       0      0      0     0     0      0   \n",
            "6200  ...       0       0       0       0      0      0     0     0      0   \n",
            "\n",
            "      ZYX  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "...   ...  \n",
            "6196    0  \n",
            "6197    0  \n",
            "6198    0  \n",
            "6199    0  \n",
            "6200    0  \n",
            "\n",
            "[6201 rows x 4386 columns]\n",
            "             ID  A2M  AAAS  AADAT  AARS1  ABAT  ABCA1  ABCA2  ABCA3  ABCA4  \\\n",
            "0     TEST_0000    0     0      0      0     0      0      0      0      0   \n",
            "1     TEST_0001    0     0      0      0     0      1      0      0      0   \n",
            "2     TEST_0002    0     0      0      0     0      0      0      0      0   \n",
            "3     TEST_0003    0     0      0      0     0      0      0      0      0   \n",
            "4     TEST_0004    0     0      0      0     0      0      0      0      0   \n",
            "...         ...  ...   ...    ...    ...   ...    ...    ...    ...    ...   \n",
            "2541  TEST_2541    0     0      0      0     0      0      0      0      0   \n",
            "2542  TEST_2542    0     0      0      0     0      0      0      0      0   \n",
            "2543  TEST_2543    0     0      0      0     0      1      0      1      1   \n",
            "2544  TEST_2544    0     0      0      0     0      0      0      0      1   \n",
            "2545  TEST_2545    0     0      0      0     0      0      0      0      0   \n",
            "\n",
            "      ...  ZNF292  ZNF365  ZNF639  ZNF707  ZNFX1  ZNRF4  ZPBP  ZW10  ZWINT  \\\n",
            "0     ...       0       0       0       0      0      0     0     0      0   \n",
            "1     ...       0       0       0       0      0      1     0     0      0   \n",
            "2     ...       0       0       0       0      0      0     0     0      0   \n",
            "3     ...       0       0       0       0      0      0     0     0      0   \n",
            "4     ...       0       0       0       0      0      0     0     0      0   \n",
            "...   ...     ...     ...     ...     ...    ...    ...   ...   ...    ...   \n",
            "2541  ...       0       0       0       0      0      0     0     0      0   \n",
            "2542  ...       0       0       0       0      0      0     0     0      0   \n",
            "2543  ...       1       1       0       0      0      0     1     1      0   \n",
            "2544  ...       0       0       0       0      0      0     0     0      0   \n",
            "2545  ...       0       0       0       0      0      0     0     0      0   \n",
            "\n",
            "      ZYX  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "...   ...  \n",
            "2541    0  \n",
            "2542    0  \n",
            "2543    0  \n",
            "2544    0  \n",
            "2545    0  \n",
            "\n",
            "[2546 rows x 4385 columns]\n"
          ]
        }
      ],
      "source": [
        "print(train)\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv('data/train_be.csv', index=False)\n",
        "test.to_csv('data/test_be.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0jX81ay2j3F"
      },
      "source": [
        "### importance feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWpvcbYCfQVo",
        "outputId": "ebab8387-7d85-4277-c298-0cc4ffe8d0e6"
      },
      "outputs": [],
      "source": [
        "# 데이터 분리\n",
        "X = train.drop(columns=['ID', 'SUBCLASS'])\n",
        "y = train['SUBCLASS']\n",
        "\n",
        "# Label Encoding for SUBCLASS (암 유형)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced_subsample')\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 중요도 출력\n",
        "importances = rf.feature_importances_\n",
        "importance_df = pd.DataFrame({'Gene': X.columns, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 상위 n개 유전자 출력\n",
        "print(importance_df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idUMGaxgi6an",
        "outputId": "a082ab47-0492-49dc-da34-f6a1daf655f8"
      },
      "outputs": [],
      "source": [
        "# 중요도가 높은 상위 n개의 유전자 리스트\n",
        "top_genes = importance_df['Gene'].head(30).tolist()\n",
        "print(top_genes)\n",
        "\n",
        "# 상위 n개의 유전자만 추출\n",
        "X_top = X[top_genes]\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_top, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모든 열을 숫자형으로 변환 (바이너리 인코딩 후)\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_val = X_val.apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 기존 리스트들\n",
        "original = ['BRAF', 'IDH1', 'VHL', 'PIK3CA', 'TP53', 'APC', 'PTEN', 'NPM1', 'ATRX', \n",
        "            'CTNNB1', 'GATA3', 'CDH1', 'EGFR', 'PCLO', 'SPOP', 'MAP3K1', 'CDKN2A', \n",
        "            'RYR2', 'KMT2D', 'SYNE1', 'SPTA1', 'KIT', 'NF1', 'MXRA5', 'NOTCH1', \n",
        "            'IDH2', 'RYR1', 'PABPC1', 'DST', 'HRAS']\n",
        "\n",
        "balanced = ['BRAF', 'IDH1', 'TP53', 'VHL', 'APC', 'NPM1', 'PIK3CA', 'PTEN', 'ATRX', \n",
        "            'CTNNB1', 'CDKN2A', 'PCLO', 'KMT2D', 'LRIG1', 'RYR2', 'SPOP', 'EGFR', \n",
        "            'KIT', 'SYNE1', 'ERCC2', 'SPTA1', 'IDH2', 'NF1', 'HRAS', 'FBXW7', 'NOTCH1', \n",
        "            'GATA3', 'CDH1', 'CEBPA', 'DMD']\n",
        "\n",
        "balanced_subsample = ['IDH1', 'BRAF', 'TP53', 'VHL', 'APC', 'NPM1', 'PIK3CA', 'PTEN', 'CTNNB1', \n",
        "                      'ATRX', 'CDKN2A', 'PCLO', 'RYR2', 'SPOP', 'KMT2D', 'KIT', 'LRIG1', 'SYNE1', \n",
        "                      'EGFR', 'ERCC2', 'SPTA1', 'IDH2', 'NF1', 'HRAS', 'FBXW7', 'CEBPA', 'GATA3', \n",
        "                      'NOTCH1', 'DMD', 'CDH1']\n",
        "\n",
        "# 세 리스트의 합집합 구하기\n",
        "top_genes = list(set(original) | set(balanced) | set(balanced_subsample))\n",
        "\n",
        "# 결과 출력\n",
        "print(sorted(top_genes))\n",
        "\n",
        "# 상위 n개의 유전자만 추출\n",
        "X_top = X[top_genes]\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_top, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모든 열을 숫자형으로 변환 (바이너리 인코딩 후)\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
        "X_val = X_val.apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9YOoM1t2q08"
      },
      "source": [
        "### RF, XGB, LGBM train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = np.unique(y_train)\n",
        "class_counts = np.bincount(y_train)\n",
        "sqrt_class_weights = np.sqrt(class_counts.sum() / class_counts)\n",
        "class_weight_dict = dict(zip(classes, sqrt_class_weights))\n",
        "\n",
        "# 클래스 가중치 딕셔너리 출력\n",
        "print(\"Class Weights Dictionary:\", class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAU4hmHIfQXe",
        "outputId": "e473faa7-3b65-4215-c780-caaa35f3de75"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest 모델 학습\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight_dict)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = rf.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inUHuxQfQZh",
        "outputId": "a3bf0646-cd14-4af9-905f-d8106eff5f56"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#\"\"\"balanced\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
        "#\"\"\"\n",
        "\n",
        "\"\"\"sqrtbalanced\n",
        "classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "sqrt_class_weights = np.sqrt(class_counts.sum() / class_counts)\n",
        "class_weight_dict = dict(zip(classes, sqrt_class_weights))\n",
        "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# XGBoost 모델 학습\n",
        "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = xgb.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbQtsOOLiSMK",
        "outputId": "cc6ab2d3-0094-4a12-edc5-8af03bd258c5"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# LightGBM 모델 학습\n",
        "lgbm = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, min_gain_to_split=0.01, class_weight=class_weight_dict)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = lgbm.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"LightGBM Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtadJKWuoCue"
      },
      "source": [
        "### test predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dz6bNYKiSOf",
        "outputId": "4aad6d4e-2a92-42cb-d375-3295c42b614e"
      },
      "outputs": [],
      "source": [
        "# WT는 0, 변이는 1로 변환하는 함수\n",
        "test_binary = test.replace('WT', 0)\n",
        "test_binary.iloc[:, 1:] = test_binary.iloc[:, 1:].applymap(lambda x: 1 if x != 0 else 0)\n",
        "print(test_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrvOFIRhomzf",
        "outputId": "2068c348-40aa-42dc-89bc-5500e8c7cac7"
      },
      "outputs": [],
      "source": [
        "X_test = test.drop(columns=['ID'])\n",
        "\n",
        "# 상위 n개의 유전자만 추출\n",
        "X_test_filtered = X_test[top_genes]\n",
        "X_test_filtered = X_test_filtered.apply(pd.to_numeric, errors='coerce')\n",
        "print(X_test_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrrnoR_jiSQk",
        "outputId": "2f887aea-1035-4c96-d6cf-975bfec1251b"
      },
      "outputs": [],
      "source": [
        "# 예측 및 평가\n",
        "y_pred_rf = rf.predict(X_test_filtered)\n",
        "y_pred_xgb = xgb.predict(X_test_filtered)\n",
        "y_pred_lgbm = lgbm.predict(X_test_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4NFgqh9iSSp",
        "outputId": "64fef345-4adc-4925-da0b-c24ea275b908"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('open/sample_submission.csv')\n",
        "print(\"predictions의 길이:\", len(y_pred_rf), len(y_pred_xgb), len(y_pred_lgbm))\n",
        "print(\"submisson의 길이:\", len(submission))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "981rn1g5iSUf"
      },
      "outputs": [],
      "source": [
        "predictions_rf = y_pred_rf.ravel()  # 또는 predictions.flatten()\n",
        "predictions_rf = le.inverse_transform(predictions_rf)\n",
        "submission[\"SUBCLASS\"] = predictions_rf\n",
        "submission.to_csv('submission_rf_.csv', encoding='UTF-8-sig', index=False)\n",
        "\n",
        "predictions_xgb = y_pred_xgb.ravel()  # 또는 predictions.flatten()\n",
        "predictions_xgb = le.inverse_transform(predictions_xgb)\n",
        "submission[\"SUBCLASS\"] = predictions_xgb\n",
        "submission.to_csv('submission_xgb_.csv', encoding='UTF-8-sig', index=False)\n",
        "\n",
        "predictions_lgbm = y_pred_lgbm.ravel()  # 또는 predictions.flatten()\n",
        "predictions_lgbm = le.inverse_transform(predictions_lgbm)\n",
        "submission[\"SUBCLASS\"] = predictions_lgbm\n",
        "submission.to_csv('submission_lgbm_.csv', encoding='UTF-8-sig', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### result\n",
        "**바이너리 인코딩**: 변이가 존재하면 1, 없으면 0으로 인코딩.\n",
        "\n",
        "→ 상위 30개로 RF(**0.21816**), XGB(**0.22777**), LGBM(**0.23187**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCuYuCJf25NQ"
      },
      "source": [
        "## 2 One-Hot Encoding\n",
        "wt, silent, missense, indel, frameshift, nonsense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 데이터 로드\n",
        "train = pd.read_csv('open/train.csv')\n",
        "test = pd.read_csv('open/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tSXZtcV5MDG",
        "outputId": "8fe936f5-cf26-4bff-a310-25ccdfc436ba"
      },
      "outputs": [],
      "source": [
        "# NaN 값을 'WT'로 치환\n",
        "train.fillna('WT', inplace=True)\n",
        "test.fillna('WT', inplace=True)\n",
        "\n",
        "train_nan = train.isna().sum().sum()\n",
        "print(f\"처리 후 train NaN 개수: {train_nan}\")\n",
        "\n",
        "test_nan = test.isna().sum().sum()\n",
        "print(f\"처리 후 test NaN 개수: {test_nan}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kBSZNLlW62Vu"
      },
      "outputs": [],
      "source": [
        "def process_value(value):\n",
        "    # 0. WT 그대로 유지\n",
        "    if value == 'WT':\n",
        "        return [1, 0, 0, 0, 0, 0]\n",
        "\n",
        "    # 1. 띄어쓰기 기준으로 변이 파트 분리\n",
        "    parts = value.split()\n",
        "\n",
        "    # WT, silent, missense, indel, frameshift, nonsense\n",
        "    processed_parts = [0, 0, 0, 0, 0, 0]\n",
        "\n",
        "    for part in parts:\n",
        "        # 1.1 WT: 0\n",
        "        if part == 'WT':\n",
        "            processed_parts[0] = 1\n",
        "            continue\n",
        "\n",
        "        # 1.2 알파벳 + 숫자 + 알파벳\n",
        "        elif re.match(r'^([A-Za-z*-]*)\\d+([A-Za-z*-]*)$', part):\n",
        "            match = re.match(r'^([A-Za-z*-]*)\\d+([A-Za-z*-]*)$', part)\n",
        "            prefix = match.group(1)   # 숫자 앞의 문자 그룹\n",
        "            suffix = match.group(2)   # 숫자 뒤의 문자 그룹\n",
        "\n",
        "            # 1.2.1 숫자 앞뒤의 문자 그룹이 같으면 silent\n",
        "            if prefix.isupper() and suffix.isupper() and prefix == suffix:\n",
        "                processed_parts[1] = 1\n",
        "\n",
        "            # 1.2.2 앞뒤 문자 그룹이 다르면 missense\n",
        "            elif prefix.isupper() and suffix.isupper() and prefix != suffix:\n",
        "                processed_parts[2] = 1\n",
        "\n",
        "            # 1.2.3 뒤의 문자 그룹에 '*'이 들어가면 nonsense\n",
        "            elif '*' in suffix:\n",
        "                processed_parts[5] = 1\n",
        "\n",
        "            # 1.2.4 뒤의 문자 그룹에 'fs'가 들어가면 frameshift\n",
        "            elif 'fs' in suffix:\n",
        "                processed_parts[4] = 1\n",
        "\n",
        "            # 1.2.5 뒤에 문자 그룹에 'del'이나 'ins'이 들어가면 indel\n",
        "            elif 'del' in suffix or 'ins' in suffix or not(suffix):\n",
        "                processed_parts[3] = 1\n",
        "\n",
        "            # 1.2.7 예외사항 출력\n",
        "            else:\n",
        "                print(part)\n",
        "\n",
        "        # 1.3 숫자_숫자알파벳>알파벳\n",
        "        elif re.match(r'^(\\d+)_(\\d+)([A-Za-z*-]+>[A-Za-z*-]+|del)$', part):\n",
        "            match = re.match(r'^(\\d+)_(\\d+)([A-Za-z*-]+>[A-Za-z*-]+|del)$', part)\n",
        "            prenum = int(match.group(1))  # 앞 위치\n",
        "            postnum = int(match.group(2))  # 뒷 위치\n",
        "            variant = match.group(3)  # 변이 정보 그룹\n",
        "\n",
        "            # 1.3.1 >가 있는 경우\n",
        "            if '>' in variant:\n",
        "                before, after = variant.split('>')  # '>' 기준으로 나눔\n",
        "\n",
        "                # 1.3.1.1 문자 그룹이 같은 경우 -> silent\n",
        "                if before.isupper() and after.isupper() and before == after:\n",
        "                    processed_parts[1] = 1\n",
        "\n",
        "                # 1.3.1.2 *가 있는 경우 -> nonsense\n",
        "                elif '*' in after:\n",
        "                    processed_parts[5] = 1\n",
        "\n",
        "                # 1.3.1.3 문자 그룹이 다른 경우 -> missense\n",
        "                elif before.isupper() and after.isupper() and before != after:\n",
        "                    processed_parts[2] = 1\n",
        "\n",
        "                else:\n",
        "                    print(part)\n",
        "\n",
        "            # 1.3.2 > 대신 'del'이 있는 경우 -> indel\n",
        "            elif 'del' in variant:\n",
        "                processed_parts[3] = 1\n",
        "\n",
        "            # 1.3.3 예외사항 출력\n",
        "            else :\n",
        "                print(part)\n",
        "\n",
        "        # 1.4 알파벳숫자_알파벳숫자변이정보\n",
        "        elif re.match(r'^([A-Za-z]+)(\\d+)_([A-Za-z]+)?(\\d+)([A-Za-z]+)$', part):\n",
        "            match = re.match(r'^([A-Za-z]+)(\\d+)_([A-Za-z]+)?(\\d+)([A-Za-z]+)$', part)\n",
        "            prenum = int(match.group(2))   # 앞 위치\n",
        "            postnum = int(match.group(4))  # 뒷 위치\n",
        "            variant = match.group(5)  # 변이정보\n",
        "\n",
        "            # 1.4.1 'delins'가 있는 경우 -> indel\n",
        "            if 'del' in variant or 'ins' in variant:\n",
        "                processed_parts[3] = 1\n",
        "\n",
        "            # 1.4.4 예외사항 출력\n",
        "            else :\n",
        "                print(part)\n",
        "\n",
        "    return processed_parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKDdoVt_8FQU",
        "outputId": "37f967f6-8222-4ea1-ea04-3a5de23cd647"
      },
      "outputs": [],
      "source": [
        "# train 데이터프레임 전처리\n",
        "for col in train.columns[2:]:  # ID와 SUBCLASS 제외\n",
        "    train[col] = train[col].apply(process_value)\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(train.iloc[:, 2:].values)\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORPG3TIq8Fln",
        "outputId": "458402f6-7dde-448c-d7b1-3485be4db01e"
      },
      "outputs": [],
      "source": [
        "# test 데이터프레임 전처리\n",
        "for col in test.columns[1:]:  # ID 제외\n",
        "    test[col] = test[col].apply(process_value)\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(test.iloc[:, 1:].values)\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv('train_oh.csv', index=False)\n",
        "test.to_csv('test_oh.csv',  index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### importance feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UlVrID-HdyN",
        "outputId": "7d2bbe23-e2d7-427a-88e1-33f146c5de4d"
      },
      "outputs": [],
      "source": [
        "X = test.drop(columns=['ID'])\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(X.values)\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 현재 시간을 출력하는 함수\n",
        "def print_with_time(*messages):\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    message = ' '.join(map(str, messages))  # 튜플 대신 문자열로 변환\n",
        "    print(f\"[{current_time}] {message}\")\n",
        "\n",
        "# Random Forest 모델 설정\n",
        "def compute_feature_importance(X_part, y):\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_part, y)\n",
        "    importances = rf.feature_importances_\n",
        "    return pd.DataFrame({'Feature': X_part.columns, 'Importance': importances})\n",
        "\n",
        "# 데이터 분할\n",
        "def split_features(X, step):\n",
        "    for i in range(0, X.shape[1], step):\n",
        "        yield i, X.iloc[:, i:i + step]\n",
        "\n",
        "def calculate_total_importance(X, y, step):\n",
        "    importance_list = []\n",
        "    for i, X_part in split_features(X, step):\n",
        "        print_with_time(f\"{i//step + 1}/22 part start\")\n",
        "        \n",
        "        # 각 리스트를 개별 열로 확장\n",
        "        X_expanded = pd.concat([X_part[col].apply(pd.Series).add_prefix(f'{col}_') for col in X_part.columns], axis=1)\n",
        "        print_with_time(f\"{i//step + 1}/22 part expanded done\")\n",
        "        importance_df = compute_feature_importance(X_expanded, y)\n",
        "        print_with_time(f\"{i//step + 1}/22 part importance done\")\n",
        "        importance_list.append(importance_df)\n",
        "        print_with_time(f\"{i//step + 1}/22 part done\")\n",
        "    \n",
        "    return pd.concat(importance_list).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# y는 SUBCLASS, X는 4384개의 피처\n",
        "X = train.drop(columns=['ID', 'SUBCLASS'])\n",
        "y = train['SUBCLASS']\n",
        "\n",
        "# Label Encoding for SUBCLASS (암 유형)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "importance_result = calculate_total_importance(X, y_encoded, step=200)\n",
        "\n",
        "# 상위 20개 특성 출력\n",
        "print(importance_result.head(20))\n",
        "\n",
        "# importance_result를 파일로 저장하는 코드 추가\n",
        "importance_result.to_csv('importance_result.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "importance_result = pd.read_csv('importance_result.csv')\n",
        "top_500 = importance_result.head(500)\n",
        "gene_names = top_500['Feature'].apply(lambda x: x.split('_')[0]).unique()\n",
        "\n",
        "print(\"important genes: \", gene_names)\n",
        "print(\"genes num: \", len(gene_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF, XGB, LGBM train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = train[gene_names]\n",
        "X_expanded = pd.concat([X[col].apply(pd.Series).add_prefix(f'{col}_') for col in X.columns], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_expanded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_expanded, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = np.unique(y_train)\n",
        "class_counts = np.bincount(y_train)\n",
        "sqrt_class_weights = np.sqrt(class_counts.sum() / class_counts)\n",
        "class_weight_dict = dict(zip(classes, sqrt_class_weights))\n",
        "\n",
        "# 클래스 가중치 딕셔너리 출력\n",
        "print(\"Class Weights Dictionary:\", class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 클래스 가중치를 0.5 단위로 반올림\n",
        "rounded_class_weight_dict = {k: round(v * 2) / 2 for k, v in class_weight_dict.items()}\n",
        "\n",
        "# 클래스 가중치 딕셔너리 출력\n",
        "print(\"Rounded Class Weights Dictionary:\", rounded_class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes_to_increase = [24]\n",
        "for cls in classes_to_increase:\n",
        "    if cls in rounded_class_weight_dict:\n",
        "        rounded_class_weight_dict[cls] += 0.10\n",
        "\n",
        "# 클래스 가중치 딕셔너리 출력\n",
        "print(\"Updated Class Weights Dictionary:\", rounded_class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest 모델 학습\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=rounded_class_weight_dict)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = rf.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\"\"\" balanced\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
        "\"\"\"\n",
        "\n",
        "#\"\"\"sqrtbalanced\n",
        "classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "sqrt_class_weights = np.sqrt(class_counts.sum() / class_counts)\n",
        "class_weight_dict = dict(zip(classes, sqrt_class_weights))\n",
        "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
        "#\"\"\"\n",
        "\n",
        "# XGBoost 모델 학습\n",
        "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = xgb.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# LightGBM 모델 학습\n",
        "lgbm = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, min_gain_to_split=0.01, class_weight=rounded_class_weight_dict)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = lgbm.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"LightGBM Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### test predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = test[gene_names]\n",
        "X_test_expanded = pd.concat([X_test[col].apply(pd.Series).add_prefix(f'{col}_') for col in X_test.columns], axis=1)\n",
        "\n",
        "print(X_test_expanded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예측 및 평가\n",
        "y_pred_rf = rf.predict(X_test_expanded)\n",
        "y_pred_xgb = xgb.predict(X_test_expanded)\n",
        "y_pred_lgbm = lgbm.predict(X_test_expanded)\n",
        "\n",
        "submission = pd.read_csv('open/sample_submission.csv')\n",
        "print(\"predictions의 길이:\", len(y_pred_rf), len(y_pred_xgb), len(y_pred_lgbm))\n",
        "print(\"submisson의 길이:\", len(submission))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_rf = y_pred_rf.ravel()  # 또는 predictions.flatten()\n",
        "predictions_rf = le.inverse_transform(predictions_rf)\n",
        "submission[\"SUBCLASS\"] = predictions_rf\n",
        "submission.to_csv('submission_rf_oh.csv', encoding='UTF-8-sig', index=False)\n",
        "\n",
        "predictions_xgb = y_pred_xgb.ravel()  # 또는 predictions.flatten()\n",
        "predictions_xgb = le.inverse_transform(predictions_xgb)\n",
        "submission[\"SUBCLASS\"] = predictions_xgb\n",
        "submission.to_csv('submission_xgb_oh.csv', encoding='UTF-8-sig', index=False)\n",
        "\n",
        "predictions_lgbm = y_pred_lgbm.ravel()  # 또는 predictions.flatten()\n",
        "predictions_lgbm = le.inverse_transform(predictions_lgbm)\n",
        "submission[\"SUBCLASS\"] = predictions_lgbm\n",
        "submission.to_csv('submission_lgbm_oh.csv', encoding='UTF-8-sig', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### result\n",
        "**원핫 인코딩**: WT = _0, silent = _1, missens = _2, indel = _3, frameshift = _4, nonsense = _5\n",
        "\n",
        "→ 상위 30개로 RF(**0.19896**), XGB(**0.20651**), LGBM(**0.20746**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 label Encoding\n",
        "- wt, silent -> 1\n",
        "- missense -> 2\n",
        "- indel -> 3\n",
        "- frameshift -> 4\n",
        "- nonsense -> 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 데이터 로드\n",
        "train = pd.read_csv('train_le.csv')\n",
        "test = pd.read_csv('test_le.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(train)\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NaN 값을 'WT'로 치환\n",
        "train.fillna('WT', inplace=True)\n",
        "test.fillna('WT', inplace=True)\n",
        "\n",
        "train_nan = train.isna().sum().sum()\n",
        "print(f\"처리 후 train NaN 개수: {train_nan}\")\n",
        "\n",
        "test_nan = test.isna().sum().sum()\n",
        "print(f\"처리 후 test NaN 개수: {test_nan}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_value_le(value):\n",
        "    # 0. WT 그대로 유지\n",
        "    if value == 'WT':\n",
        "        return 1\n",
        "\n",
        "    # 1. 띄어쓰기 기준으로 변이 파트 분리\n",
        "    parts = value.split()\n",
        "\n",
        "    # WT, silent, missense, indel, frameshift, nonsense\n",
        "    processed_value = 0\n",
        "\n",
        "    for part in parts:\n",
        "        # 1.1 WT: 0\n",
        "        if part == 'WT':\n",
        "            processed_value = max(processed_value, 1)\n",
        "            continue\n",
        "\n",
        "        # 1.2 알파벳 + 숫자 + 알파벳\n",
        "        elif re.match(r'^([A-Za-z*-]*)\\d+([A-Za-z*-]*)$', part):\n",
        "            match = re.match(r'^([A-Za-z*-]*)\\d+([A-Za-z*-]*)$', part)\n",
        "            prefix = match.group(1)   # 숫자 앞의 문자 그룹\n",
        "            suffix = match.group(2)   # 숫자 뒤의 문자 그룹\n",
        "\n",
        "            # 1.2.1 숫자 앞뒤의 문자 그룹이 같으면 silent\n",
        "            if prefix.isupper() and suffix.isupper() and prefix == suffix:\n",
        "                processed_value = max(processed_value, 1)\n",
        "\n",
        "            # 1.2.2 앞뒤 문자 그룹이 다르면 missense\n",
        "            elif prefix.isupper() and suffix.isupper() and prefix != suffix:\n",
        "                processed_value = max(processed_value, 2)\n",
        "\n",
        "            # 1.2.3 뒤의 문자 그룹에 '*'이 들어가면 nonsense\n",
        "            elif '*' in suffix:\n",
        "                processed_value = max(processed_value, 5)\n",
        "\n",
        "            # 1.2.4 뒤의 문자 그룹에 'fs'가 들어가면 frameshift\n",
        "            elif 'fs' in suffix:\n",
        "                processed_value = max(processed_value, 4)\n",
        "\n",
        "            # 1.2.5 뒤에 문자 그룹에 'del'이나 'ins'이 들어가면 indel\n",
        "            elif 'del' in suffix or 'ins' in suffix or not(suffix):\n",
        "                processed_value = max(processed_value, 3)\n",
        "\n",
        "            # 1.2.7 예외사항 출력\n",
        "            else:\n",
        "                print(part)\n",
        "\n",
        "        # 1.3 숫자_숫자알파벳>알파벳\n",
        "        elif re.match(r'^(\\d+)_(\\d+)([A-Za-z*-]+>[A-Za-z*-]+|del)$', part):\n",
        "            match = re.match(r'^(\\d+)_(\\d+)([A-Za-z*-]+>[A-Za-z*-]+|del)$', part)\n",
        "            prenum = int(match.group(1))  # 앞 위치\n",
        "            postnum = int(match.group(2))  # 뒷 위치\n",
        "            variant = match.group(3)  # 변이 정보 그룹\n",
        "\n",
        "            # 1.3.1 >가 있는 경우\n",
        "            if '>' in variant:\n",
        "                before, after = variant.split('>')  # '>' 기준으로 나눔\n",
        "\n",
        "                # 1.3.1.1 문자 그룹이 같은 경우 -> silent\n",
        "                if before.isupper() and after.isupper() and before == after:\n",
        "                    processed_value = max(processed_value, 1)\n",
        "\n",
        "                # 1.3.1.2 *가 있는 경우 -> nonsense\n",
        "                elif '*' in after:\n",
        "                    processed_value = max(processed_value, 5)\n",
        "\n",
        "                # 1.3.1.3 문자 그룹이 다른 경우 -> missense\n",
        "                elif before.isupper() and after.isupper() and before != after:\n",
        "                    processed_value = max(processed_value, 2)\n",
        "\n",
        "                else:\n",
        "                    print(part)\n",
        "\n",
        "            # 1.3.2 > 대신 'del'이 있는 경우 -> indel\n",
        "            elif 'del' in variant:\n",
        "                processed_value = max(processed_value, 3)\n",
        "\n",
        "            # 1.3.3 예외사항 출력\n",
        "            else :\n",
        "                print(part)\n",
        "\n",
        "        # 1.4 알파벳숫자_알파벳숫자변이정보\n",
        "        elif re.match(r'^([A-Za-z]+)(\\d+)_([A-Za-z]+)?(\\d+)([A-Za-z]+)$', part):\n",
        "            match = re.match(r'^([A-Za-z]+)(\\d+)_([A-Za-z]+)?(\\d+)([A-Za-z]+)$', part)\n",
        "            prenum = int(match.group(2))   # 앞 위치\n",
        "            postnum = int(match.group(4))  # 뒷 위치\n",
        "            variant = match.group(5)  # 변이정보\n",
        "\n",
        "            # 1.4.1 'delins'가 있는 경우 -> indel\n",
        "            if 'del' in variant or 'ins' in variant:\n",
        "                processed_value = max(processed_value, 3)\n",
        "\n",
        "            # 1.4.4 예외사항 출력\n",
        "            else :\n",
        "                print(part)\n",
        "\n",
        "    return processed_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train 데이터프레임 전처리\n",
        "for col in train.columns[2:]:  # ID와 SUBCLASS 제외\n",
        "    train[col] = train[col].apply(process_value_le)\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(train.iloc[:, 2:].values)\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test 데이터프레임 전처리\n",
        "for col in test.columns[1:]:  # ID 제외\n",
        "    test[col] = test[col].apply(process_value_le)\n",
        "\n",
        "# 모든 열에서 유니크한 값 추출\n",
        "unique_values = np.unique(test.iloc[:, 1:].values)\n",
        "print(unique_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.to_csv('train_le.csv', index=False)\n",
        "test.to_csv('test_le.csv',  index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### importance feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 분리\n",
        "X = train.drop(columns=['ID', 'SUBCLASS'])\n",
        "y = train['SUBCLASS']\n",
        "\n",
        "# Label Encoding for SUBCLASS (암 유형)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 학습\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced_subsample')\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 중요도 출력\n",
        "importances = rf.feature_importances_\n",
        "importance_df = pd.DataFrame({'Gene': X.columns, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 상위 n개 유전자 출력\n",
        "print(importance_df.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 중요도가 높은 상위 n개의 유전자 리스트\n",
        "top_genes = importance_df['Gene'].head(30).tolist()\n",
        "print(top_genes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normal = ['BRAF', 'IDH1', 'VHL', 'APC', 'TP53', 'PIK3CA', 'ATRX', 'GATA3', 'PTEN', 'NPM1', 'CDH1', 'CTNNB1', 'EGFR', 'MAP3K1', 'CDKN2A', 'PCLO', 'KMT2D', 'SPOP', 'RYR2', 'SYNE1', 'NF1', 'SPTA1', 'KIT', 'NOTCH1', 'MXRA5', 'IDH2', 'RB1', 'FBXW7', 'DST', 'RYR1']\n",
        "balanced = ['BRAF', 'IDH1', 'APC', 'TP53', 'VHL', 'NPM1', 'PTEN', 'PIK3CA', 'ATRX', 'CTNNB1', 'KMT2D', 'CDKN2A', 'PCLO', 'RYR2', 'LRIG1', 'NF1', 'SPOP', 'SYNE1', 'ERCC2', 'KIT', 'EGFR', 'GATA3', 'CDH1', 'SPTA1', 'FBXW7', 'IDH2', 'NOTCH1', 'HRAS', 'RB1', 'CEBPA']\n",
        "balanced_subsample = ['IDH1', 'BRAF', 'APC', 'TP53', 'VHL', 'NPM1', 'PTEN', 'PIK3CA', 'ATRX', 'CTNNB1', 'KMT2D', 'CDKN2A', 'RYR2', 'PCLO', 'NF1', 'SPOP', 'LRIG1', 'KIT', 'EGFR', 'SYNE1', 'GATA3', 'CDH1', 'ERCC2', 'SPTA1', 'RB1', 'FBXW7', 'HRAS', 'IDH2', 'DMD', 'CEBPA']\n",
        "\n",
        "# 세 리스트의 합집합 구하기\n",
        "top_genes = set(normal) | set(balanced) | set(balanced_subsample)\n",
        "\n",
        "# 합집합을 리스트로 변환\n",
        "top_genes = list(top_genes)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Union of the three lists:\", top_genes)\n",
        "print(\"Number of genes:\", len(top_genes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF, XGB, LGBM train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 상위 n개의 유전자만 추출\n",
        "X_top = X[top_genes]\n",
        "\n",
        "# 데이터 분리\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_top, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = np.unique(y_train)\n",
        "class_counts = np.bincount(y_train)\n",
        "sqrt_class_weights = np.sqrt(class_counts.sum() / class_counts)\n",
        "class_weight_dict = dict(zip(classes, sqrt_class_weights))\n",
        "\n",
        "# 클래스 가중치 딕셔너리 출력\n",
        "print(\"Class Weights Dictionary:\", class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest 모델 학습\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight_dict)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = rf.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\"\"\" balanced\n",
        "classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
        "\"\"\"\n",
        "\n",
        "#\"\"\"sqrtbalanced\n",
        "classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "sqrt_class_weights = np.sqrt(class_counts.sum() / class_counts)\n",
        "class_weight_dict = dict(zip(classes, sqrt_class_weights))\n",
        "sample_weights = np.array([class_weight_dict[label] for label in y_train])\n",
        "#\"\"\"\n",
        "\n",
        "# XGBoost 모델 학습\n",
        "xgb = XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = xgb.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# LightGBM 모델 학습\n",
        "lgbm = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, min_gain_to_split=0.01, class_weight=class_weight_dict)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# 예측 및 평가\n",
        "y_pred = lgbm.predict(X_val)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"LightGBM Accuracy: {accuracy:.4f}\")\n",
        "print()\n",
        "\n",
        "# 혼동 행렬 계산 및 출력\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.savefig('confusion_matrix.png')  # 이미지 파일로 저장\n",
        "plt.show()\n",
        "\n",
        "# 매크로 F1 스코어 계산 및 출력\n",
        "macro_f1 = f1_score(y_val, y_pred, average='macro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### test predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = test[gene_names]\n",
        "X_test_expanded = pd.concat([X_test[col].apply(pd.Series).add_prefix(f'{col}_') for col in X_test.columns], axis=1)\n",
        "\n",
        "print(X_test_expanded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 예측 및 평가\n",
        "y_pred_rf = rf.predict(X_test_expanded)\n",
        "y_pred_xgb = xgb.predict(X_test_expanded)\n",
        "y_pred_lgbm = lgbm.predict(X_test_expanded)\n",
        "\n",
        "submission = pd.read_csv('open/sample_submission.csv')\n",
        "print(\"predictions의 길이:\", len(y_pred_rf), len(y_pred_xgb), len(y_pred_lgbm))\n",
        "print(\"submisson의 길이:\", len(submission))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions_rf = y_pred_rf.ravel()  # 또는 predictions.flatten()\n",
        "predictions_rf = le.inverse_transform(predictions_rf)\n",
        "submission[\"SUBCLASS\"] = predictions_rf\n",
        "submission.to_csv('submission_rf_oh.csv', encoding='UTF-8-sig', index=False)\n",
        "\n",
        "predictions_xgb = y_pred_xgb.ravel()  # 또는 predictions.flatten()\n",
        "predictions_xgb = le.inverse_transform(predictions_xgb)\n",
        "submission[\"SUBCLASS\"] = predictions_xgb\n",
        "submission.to_csv('submission_xgb_oh.csv', encoding='UTF-8-sig', index=False)\n",
        "\n",
        "predictions_lgbm = y_pred_lgbm.ravel()  # 또는 predictions.flatten()\n",
        "predictions_lgbm = le.inverse_transform(predictions_lgbm)\n",
        "submission[\"SUBCLASS\"] = predictions_lgbm\n",
        "submission.to_csv('submission_lgbm_oh.csv', encoding='UTF-8-sig', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jDxtKj3i3zkK",
        "A8_n72Wn4Lu-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
